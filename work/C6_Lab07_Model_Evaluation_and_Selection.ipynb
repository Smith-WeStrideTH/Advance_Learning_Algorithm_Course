{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvYDy9apGRlt"
   },
   "source": [
    "# ห้องปฏิบัติการเสริม: การประเมินและเลือกโมเดล\n",
    "\n",
    "การหาปริมาณประสิทธิภาพของอัลกอริทึมการเรียนรู้และการเปรียบเทียบโมเดลต่างๆ เป็นหนึ่งในงานทั่วไปเมื่อนำการเรียนรู้ของเครื่องไปใช้ในแอปพลิเคชันในโลกแห่งความจริง ในห้องปฏิบัติการนี้ คุณจะฝึกทำสิ่งเหล่านี้โดยใช้เคล็ดลับที่แบ่งปันในชั้นเรียน โดยเฉพาะอย่างยิ่ง คุณจะ:\n",
    "\n",
    "* แยกชุดข้อมูลออกเป็นชุดฝึก ชุดตรวจสอบข้าม และชุดทดสอบ\n",
    "* ประเมินโมเดลการถดถอยและการจำแนกประเภท\n",
    "* เพิ่มคุณลักษณะพหุนามเพื่อปรับปรุงประสิทธิภาพของโมเดลการถดถอยเชิงเส้น\n",
    "* เปรียบเทียบสถาปัตยกรรมเครือข่ายประสาทเทียมหลายแบบ\n",
    "\n",
    "ห้องปฏิบัติการนี้จะช่วยให้คุณคุ้นเคยกับโค้ดที่คุณจะเห็นในการมอบหมายการเขียนโปรแกรมในสัปดาห์นี้ มาเริ่มกัน!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jj1P1kTmGRlv"
   },
   "source": [
    "## การนำเข้าและการตั้งค่าห้องปฏิบัติการ\n",
    "\n",
    "ขั้นแรก คุณจะนำเข้าแพ็คเกจที่จำเป็นสำหรับงานในห้องปฏิบัติการนี้ เรายังได้รวมคำสั่งบางอย่างเพื่อทำให้ผลลัพธ์ในภายหลังอ่านได้ง่ายขึ้นโดยการลดความยืดยาวและระงับการเตือนที่ไม่สำคัญ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/Smith-WeStrideTH/Advance_Learning_Algorithm_Course/refs/heads/main/work/deeplearning.mplstyle'\n",
    "url2 = 'https://raw.githubusercontent.com/Smith-WeStrideTH/Advance_Learning_Algorithm_Course/refs/heads/main/work/utils.py'\n",
    "url3 = 'https://raw.githubusercontent.com/Smith-WeStrideTH/Advance_Learning_Algorithm_Course/refs/heads/main/work/data/data_w3_ex1.csv'\n",
    "url4 = 'https://raw.githubusercontent.com/Smith-WeStrideTH/Advance_Learning_Algorithm_Course/refs/heads/main/work/data/data_w3_ex2.csv'\n",
    "\n",
    "response = requests.get(url)\n",
    "with open('deeplearning.mplstyle', 'wb') as f:\n",
    "  f.write(response.content)\n",
    "\n",
    "response = requests.get(url2)\n",
    "with open('utils.py', 'wb') as f:\n",
    "  f.write(response.content)\n",
    "\n",
    "response = requests.get(url3)\n",
    "data_path = Path('data')\n",
    "if not data_path.is_dir():\n",
    "  data_path.mkdir(parents=True, exist_ok=True)\n",
    "with open('data/data_w3_ex1.csv', 'wb') as f:\n",
    "  f.write(response.content)\n",
    "with open('data/data_w3_ex2.csv', 'wb') as f:\n",
    "  f.write(response.content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuHD2EOxGRlv"
   },
   "outputs": [],
   "source": [
    "# for array computations and loading data\n",
    "import numpy as np\n",
    "\n",
    "# for building linear regression models and preparing data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# for building and training neural networks\n",
    "import tensorflow as tf\n",
    "\n",
    "# custom functions\n",
    "import utils\n",
    "\n",
    "# reduce display precision on numpy arrays\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# suppress warnings\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_UnQ-tWGRlw"
   },
   "source": [
    "## การถดถอย (Regression)\n",
    "\n",
    "อันดับแรก คุณจะได้รับมอบหมายให้พัฒนาโมเดลสำหรับปัญหาการถดถอย คุณได้รับชุดข้อมูลด้านล่างซึ่งประกอบด้วยตัวอย่าง 50 ตัวอย่างของคุณลักษณะอินพุต `x` และเป้าหมายที่สอดคล้องกัน `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QLsSum08GRlx",
    "outputId": "0d843000-30bf-4a55-dcd8-cd5e42dc716e"
   },
   "outputs": [],
   "source": [
    "# Load the dataset from the text file\n",
    "data = np.loadtxt('./data/data_w3_ex1.csv', delimiter=',')\n",
    "\n",
    "# Split the inputs and outputs into separate arrays\n",
    "x = data[:,0]\n",
    "y = data[:,1]\n",
    "\n",
    "# Convert 1-D arrays into 2-D because the commands later will require it\n",
    "x = np.expand_dims(x, axis=1)\n",
    "y = np.expand_dims(y, axis=1)\n",
    "\n",
    "print(f\"the shape of the inputs x is: {x.shape}\")\n",
    "print(f\"the shape of the targets y is: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ar2jLTqlpt4x"
   },
   "source": [
    "คุณสามารถพล็อตชุดข้อมูลเพื่อดูพฤติกรรมของเป้าหมายสัมพันธ์กับอินพุต ในกรณีที่คุณต้องการตรวจสอบโค้ด คุณสามารถดูฟังก์ชัน `plot_dataset()` ได้ในไฟล์ `utils.py` นอกเหนือจากสมุดบันทึกนี้."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "VxJqex92GRlx",
    "outputId": "b6d781d1-bff3-4912-abe1-0d7fe5738b08"
   },
   "outputs": [],
   "source": [
    "# Plot the entire dataset\n",
    "utils.plot_dataset(x=x, y=y, title=\"input vs. target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbZdSoJHGRly"
   },
   "source": [
    "## แบ่งชุดข้อมูลออกเป็นชุดฝึก ชุดตรวจสอบข้าม และชุดทดสอบ\n",
    "\n",
    "ในห้องปฏิบัติการก่อนหน้านี้ คุณอาจใช้ชุดข้อมูลทั้งหมดในการฝึกโมเดลของคุณ อย่างไรก็ตาม ในทางปฏิบัติแล้ว ควรแยกส่วนหนึ่งของข้อมูลของคุณเพื่อวัดว่าโมเดลของคุณสามารถสรุปข้อมูลใหม่ได้ดีแค่ไหน ซึ่งจะช่วยให้คุณทราบว่าโมเดลได้เรียนรู้มากเกินไปกับชุดฝึกของคุณหรือไม่\n",
    "\n",
    "ตามที่กล่าวไว้ในบรรยาย เป็นเรื่องปกติที่จะแบ่งข้อมูลของคุณออกเป็นสามส่วน:\n",
    "\n",
    "* ***training set*** - ใช้ในการฝึกโมเดล\n",
    "* ***cross validation set (cross validation set หรือ validation, development, หรือ dev set)*** - ใช้ในการประเมินการกำหนดค่าโมเดลที่แตกต่างกันที่คุณกำลังเลือก ตัวอย่างเช่น คุณสามารถใช้สิ่งนี้เพื่อตัดสินใจว่าจะเพิ่มคุณลักษณะพหุนามใดลงในชุดข้อมูลของคุณ\n",
    "* ***test set*** - ใช้เพื่อให้การประมาณค่าที่เป็นธรรมเกี่ยวกับประสิทธิภาพของโมเดลที่คุณเลือกกับตัวอย่างใหม่ สิ่งนี้ไม่ควรใช้ในการตัดสินใจขณะที่คุณยังคงพัฒนาโมเดล\n",
    "\n",
    "Scikit-learn มีฟังก์ชัน [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) เพื่อแบ่งข้อมูลของคุณออกเป็นส่วนต่างๆ ดังที่กล่าวมาข้างต้น ในเซลล์โค้ดด้านล่าง คุณจะแบ่งชุดข้อมูลทั้งหมดออกเป็น 60% สำหรับการฝึก 20% สำหรับการตรวจสอบข้าม และ 20% สำหรับการทดสอบ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22JKPjmjGRly",
    "outputId": "6f02748d-e8ef-4243-d7ff-a206be7e66f5"
   },
   "outputs": [],
   "source": [
    "# Get 60% of the dataset as the training set. Put the remaining 40% in temporary variables: x_ and y_.\n",
    "x_train, x_, y_train, y_ = train_test_split(x, y, test_size=0.40, random_state=1)\n",
    "\n",
    "# Split the 40% subset above into two: one half for cross validation and the other for the test set\n",
    "x_cv, x_test, y_cv, y_test = train_test_split(x_, y_, test_size=0.50, random_state=1)\n",
    "\n",
    "# Delete temporary variables\n",
    "del x_, y_\n",
    "\n",
    "print(f\"the shape of the training set (input) is: {x_train.shape}\")\n",
    "print(f\"the shape of the training set (target) is: {y_train.shape}\\n\")\n",
    "print(f\"the shape of the cross validation set (input) is: {x_cv.shape}\")\n",
    "print(f\"the shape of the cross validation set (target) is: {y_cv.shape}\\n\")\n",
    "print(f\"the shape of the test set (input) is: {x_test.shape}\")\n",
    "print(f\"the shape of the test set (target) is: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrgciBNd1HYr"
   },
   "source": [
    "คุณสามารถพล็อตชุดข้อมูลอีกครั้งด้านล่างเพื่อดูว่าจุดใดถูกใช้เป็นข้อมูลการฝึก การตรวจสอบข้ามหรือข้อมูลทดสอบ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "yGm8JbUUzoUW",
    "outputId": "2f7227ef-9e48-4df5-d913-a5b48e92fe81"
   },
   "outputs": [],
   "source": [
    "utils.plot_train_cv_test(x_train, y_train, x_cv, y_cv, x_test, y_test, title=\"input vs. target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ayr22PeEGRly"
   },
   "source": [
    "## ปรับโมเดลเชิงเส้น\n",
    "\n",
    "ตอนนี้คุณได้แยกข้อมูลแล้ว หนึ่งในสิ่งแรกที่คุณสามารถลองทำได้คือการปรับโมเดลเชิงเส้น คุณจะทำเช่นนั้นในส่วนต่อไปด้านล่าง"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1UdF77SGRlz"
   },
   "source": [
    "### การปรับขนาดฟีเจอร์\n",
    "\n",
    "ในหลักสูตรก่อนหน้านี้ของความเชี่ยวชาญนี้ คุณได้เห็นว่า โดยปกติแล้วการปรับขนาดฟีเจอร์ (feature scaling) เป็นสิ่งที่ดีที่ควรทำเพื่อช่วยให้โมเดลของคุณบรรจบได้เร็วขึ้น โดยเฉพาะอย่างยิ่งหากฟีเจอร์อินพุตของคุณมีช่วงของค่าที่ต่างกันอย่างมาก ในบทฝึกปฏิบัติในภายหลังของบทเรียนนี้ คุณจะเพิ่มเทอมพหุนามเข้าไป ดังนั้นฟีเจอร์อินพุตของคุณจะมีช่วงที่ต่างกัน ตัวอย่างเช่น $x$ จะมีค่าตั้งแต่ประมาณ 1600 ถึง 3600 ในขณะที่ $x^2$  จะมีค่าตั้งแต่ 2.56 ล้านถึง 12.96 ล้าน\n",
    "\n",
    "สำหรับโมเดลแรกนี้ คุณจะใช้เฉพาะ x เท่านั้น แต่การฝึกฝนการปรับขนาดฟีเจอร์ตั้งแต่ตอนนี้เป็นสิ่งที่ดี เพื่อที่คุณจะสามารถนำไปใช้ในภายหลังได้ ในการนั้น คุณจะใช้คลาส  [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) จาก scikit-learn ซึ่งคำนวณคะแนน Z ของข้อมูลอินพุตของคุณ เพื่อเป็นการทบทวน คะแนน Z จะได้จากสมการ:\n",
    "\n",
    "$$ z = \\frac{x - \\mu}{\\sigma} $$\n",
    "\n",
    "โดยที่  $\\mu$ คือค่าเฉลี่ยของค่าลักษณะและ $\\sigma$ คือส่วนเบี่ยงเบนมาตรฐาน โค้ดด้านล่างแสดงวิธีการเตรียมชุดฝึกอบรมโดยใช้คลาสที่กล่าวถึง คุณสามารถพล็อตผลลัพธ์อีกครั้งเพื่อตรวจสอบว่ายังคงเป็นไปตามรูปแบบเดิมหรือไม่ กราฟใหม่ควรมีช่วงของค่าที่ลดลงสำหรับ `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "QlJ7eQ0TGRlz",
    "outputId": "ed899629-4c5e-468d-d5c8-a4b3349bd62a"
   },
   "outputs": [],
   "source": [
    "# Initialize the class\n",
    "scaler_linear = StandardScaler()\n",
    "\n",
    "# Compute the mean and standard deviation of the training set then transform it\n",
    "X_train_scaled = scaler_linear.fit_transform(x_train)\n",
    "\n",
    "print(f\"Computed mean of the training set: {scaler_linear.mean_.squeeze():.2f}\")\n",
    "print(f\"Computed standard deviation of the training set: {scaler_linear.scale_.squeeze():.2f}\")\n",
    "\n",
    "# Plot the results\n",
    "utils.plot_dataset(x=X_train_scaled, y=y_train, title=\"scaled input vs. target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzDw7PcJGRlz"
   },
   "source": [
    "### ฝึกโมเดล\n",
    "ต่อไป คุณจะสร้างและฝึกโมเดลการถดถอย สำหรับห้องปฏิบัติการนี้ คุณจะใช้คลาส  [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) แต่โปรดทราบว่ามีตัวถดถอยเชิงเส้นอื่น ๆ  [linear regressors](https://scikit-learn.org/stable/modules/classes.html#classical-linear-regressors) ที่คุณสามารถใช้ได้เช่นกัน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIol3uTkGRlz",
    "outputId": "283e5e1c-9aff-41bb-c2d3-6977861d63bd"
   },
   "outputs": [],
   "source": [
    "# Initialize the class\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "linear_model.fit(X_train_scaled, y_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8LW5leOGRlz"
   },
   "source": [
    "### การประเมินประสิทธิภาพของโมเดล\n",
    "เพื่อประเมินประสิทธิภาพของโมเดลของคุณ เราจะวัดค่าความผิดพลาดสำหรับชุดข้อมูลฝึกอบรมและชุดข้อมูลตรวจสอบข้าม (cross validation)\n",
    "\n",
    "สำหรับความผิดพลาดของการฝึกอบรม ทบทวนสูตรสำหรับการคำนวณค่าความผิดพลาดกำลังสองเฉลี่ย (mean squared error: MSE)\n",
    "\n",
    "\n",
    "$$J_{train}(\\vec{w}, b) = \\frac{1}{2m_{train}}\\left[\\sum_{i=1}^{m_{train}}(f_{\\vec{w},b}(\\vec{x}_{train}^{(i)}) - y_{train}^{(i)})^2\\right]$$\n",
    "\n",
    "Scikit-learn ยังมีฟังก์ชัน [`mean_squared_error()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) ที่คุณสามารถใช้ได้ อย่างไรก็ตาม โปรดทราบว่า [as per the documentation](https://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error)การใช้งานของ scikit-learn จะหารด้วย  `m` เท่านั้น ไม่ใช่ `2*m`, โดยที่  `m` คือจำนวนตัวอย่าง ดังที่กล่าวไว้ใน Course 1 ของความเชี่ยวชาญนี้ ( บทบรรยายฟังก์ชันต้นทุน) การหารด้วย `2m`  เป็นรูปแบบที่เราจะปฏิบัติตาม แต่การคำนวณจะยังคงทำงานได้ไม่ว่าคุณจะรวมไว้หรือไม่ ดังนั้น เพื่อให้ตรงกับสมการด้านบน คุณสามารถใช้ฟังก์ชัน scikit-learn แล้วหารด้วย 2 ดังที่แสดงด้านล่าง นอกจากนี้ เรายังรวมการวนซ้ำแบบฟังก์ชันไว้เพื่อให้คุณตรวจสอบได้ว่ามันเท่ากัน\n",
    "\n",
    "อีกสิ่งที่ต้องคำนึงถึง: เนื่องจากคุณได้ฝึกอบรมโมเดลบนค่าที่ปรับขนาดแล้ว (เช่น ใช้คะแนนมาตรฐาน) คุณควรป้อนข้อมูลชุดข้อมูลฝึกอบรมที่ปรับขนาดแล้วแทนค่าดิบด้วย\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xmuskcDhfy8z",
    "outputId": "10bb7e65-1723-4ab6-8bbf-f800e8777474"
   },
   "outputs": [],
   "source": [
    "# Feed the scaled training set and get the predictions\n",
    "yhat = linear_model.predict(X_train_scaled)\n",
    "\n",
    "# Use scikit-learn's utility function and divide by 2\n",
    "print(f\"training MSE (using sklearn function): {mean_squared_error(y_train, yhat) / 2}\")\n",
    "\n",
    "# for-loop implementation\n",
    "total_squared_error = 0\n",
    "\n",
    "for i in range(len(yhat)):\n",
    "    squared_error_i  = (yhat[i] - y_train[i])**2\n",
    "    total_squared_error += squared_error_i                                              \n",
    "\n",
    "mse = total_squared_error / (2*len(yhat))\n",
    "\n",
    "print(f\"training MSE (for-loop implementation): {mse.squeeze()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lujrQns9f-vu"
   },
   "source": [
    "คุณสามารถคำนวณ MSE สำหรับชุดการตรวจสอบแบบไขว้ได้ด้วยสมการเดียวกัน:\n",
    "$$J_{cv}(\\vec{w}, b) = \\frac{1}{2m_{cv}}\\left[\\sum_{i=1}^{m_{cv}}(f_{\\vec{w},b}(\\vec{x}_{cv}^{(i)}) - y_{cv}^{(i)})^2\\right]$$\n",
    "\n",
    "เช่นเดียวกับชุดการฝึก คุณจะต้องปรับขนาดชุดการตรวจสอบแบบไขว้ด้วย สิ่งสำคัญที่ต้องทราบเมื่อใช้ z-score คือคุณต้องใช้ค่าเฉลี่ยและส่วนเบี่ยงเบนมาตรฐานของชุดการฝึกเมื่อปรับขนาดชุดการตรวจสอบแบบไขว้ สิ่งนี้เพื่อให้แน่ใจว่าคุณสมบัติอินพุตของคุณถูกแปลงตามที่คาดหวังโดยโมเดล วิธีหนึ่งในการได้รับสัญชาตญาณคือด้วยสถานการณ์นี้:\n",
    "\n",
    "* สมมติว่าชุดการฝึกของคุณมีคุณสมบัติอินพุตเท่ากับ `500`  ซึ่งถูกปรับขนาดลงเป็น `0.5` โดยใช้ z-score\n",
    "* หลังจากการฝึก โมเดลของคุณสามารถแมปอินพุตที่ปรับขนาดแล้ว `x=0.5` ไปยังเอาต์พุตเป้าหมาย `y=300` ได้อย่างแม่นยำ \n",
    "* ตอนนี้สมมติว่าคุณใช้งานโมเดลนี้และหนึ่งในผู้ใช้ของคุณป้อนตัวอย่างเท่ากับ  `500`. \n",
    "* หากคุณรับ z-score ของตัวอย่างอินพุตนี้โดยใช้ค่าอื่นใดของค่าเฉลี่ยและส่วนเบี่ยงเบนมาตรฐาน อาจจะไม่ได้ปรับขนาดเป็น `0.5` และโมเดลของคุณอาจทำนายผิด (เช่น ไม่เท่ากับ `y=300`). \n",
    "\n",
    "คุณจะปรับขนาดชุดการตรวจสอบแบบไขว้ด้านล่างโดยใช้  `StandardScaler` เดียวกันที่คุณใช้ก่อนหน้านี้ แต่เรียก [`transform()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.transform) แทนที่จะใช้ [`fit_transform()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.fit_transform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJQbmq70GRl0",
    "outputId": "7b75d664-7cf0-4a27-c79c-3236857f444b"
   },
   "outputs": [],
   "source": [
    "# Scale the cross validation set using the mean and standard deviation of the training set\n",
    "X_cv_scaled = scaler_linear.transform(x_cv)\n",
    "\n",
    "print(f\"Mean used to scale the CV set: {scaler_linear.mean_.squeeze():.2f}\")\n",
    "print(f\"Standard deviation used to scale the CV set: {scaler_linear.scale_.squeeze():.2f}\")\n",
    "\n",
    "# Feed the scaled cross validation set\n",
    "yhat = linear_model.predict(X_cv_scaled)\n",
    "\n",
    "# Use scikit-learn's utility function and divide by 2\n",
    "print(f\"Cross validation MSE: {mean_squared_error(y_cv, yhat) / 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZtb_blcGRl0"
   },
   "source": [
    "## Adding Polynomial Features (การเพิ่มคุณสมบัติพหุนาม)\n",
    "\n",
    "จากกราฟก่อนหน้านี้ คุณอาจสังเกตเห็นว่าเป้าหมาย `y` เพิ่มขึ้นอย่างรวดเร็วขึ้นที่ค่า `x` ที่ต่ำกว่าเมื่อเทียบกับค่าที่สูงกว่า เส้นตรงอาจไม่ใช่ทางเลือกที่ดีที่สุดเพราะเป้าหมาย `y` ดูเหมือนจะแบนราบเมื่อ `x`  เพิ่มขึ้น ตอนนี้คุณมีค่าเหล่านี้ของ MSE การฝึกและการตรวจสอบข้ามจากโมเดลเชิงเส้น คุณสามารถลองเพิ่มคุณสมบัติพหุนามเพื่อดูว่าคุณสามารถได้ผลลัพธ์ที่ดีขึ้นหรือไม่ โค้ดส่วนใหญ่จะเหมือนกัน แต่จะมีขั้นตอนการเตรียมข้อมูลเพิ่มเติมเล็กน้อย มาดูด้านล่างกัน"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### สร้างฟีเจอร์เพิ่มเติม\n",
    "\n",
    "อันดับแรก คุณจะสร้างฟีเจอร์พหุนามจากชุดข้อมูลฝึกของคุณ โค้ดด้านล่างแสดงวิธีการทำโดยใช้คลาส [`PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)  มันจะสร้างฟีเจอร์อินพุตใหม่ซึ่งมีค่ากำลังสองของอินพุต `x` (เช่น degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rt1FCgQOGRl0"
   },
   "outputs": [],
   "source": [
    "# Instantiate the class to make polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Compute the number of features and transform the training set\n",
    "X_train_mapped = poly.fit_transform(x_train)\n",
    "\n",
    "# Preview the first 5 elements of the new training set. Left column is `x` and right column is `x^2`\n",
    "# Note: The `e+<number>` in the output denotes how many places the decimal point should \n",
    "# be moved. For example, `3.24e+03` is equal to `3240`\n",
    "print(X_train_mapped[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากนั้นคุณจะปรับขนาดอินพุตตามเดิมเพื่อลดช่วงของค่า"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVJUmPQKGRl1"
   },
   "outputs": [],
   "source": [
    "# Instantiate the class\n",
    "scaler_poly = StandardScaler()\n",
    "\n",
    "# Compute the mean and standard deviation of the training set then transform it\n",
    "X_train_mapped_scaled = scaler_poly.fit_transform(X_train_mapped)\n",
    "\n",
    "# Preview the first 5 elements of the scaled training set.\n",
    "print(X_train_mapped_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากนั้นคุณสามารถดำเนินการฝึกโมเดล หลังจากนั้น คุณจะวัดประสิทธิภาพของโมเดลกับชุดการตรวจสอบข้ามเหมือนก่อน คุณควรตรวจสอบให้แน่ใจว่าได้ดำเนินการแปลงข้อมูลเหมือนกับที่คุณทำในชุดการฝึก คุณจะเพิ่มจำนวนคุณลักษณะพหุนามเท่ากันจากนั้นปรับขนาดช่วงของค่า"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WO7rK-f9GRl1",
    "outputId": "12a61725-7eab-40c0-91c2-2acc9f1c5d2a"
   },
   "outputs": [],
   "source": [
    "# Initialize the class\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_mapped_scaled, y_train )\n",
    "\n",
    "# Compute the training MSE\n",
    "yhat = model.predict(X_train_mapped_scaled)\n",
    "print(f\"Training MSE: {mean_squared_error(y_train, yhat) / 2}\")\n",
    "\n",
    "# Add the polynomial features to the cross validation set\n",
    "X_cv_mapped = poly.transform(x_cv)\n",
    "\n",
    "# Scale the cross validation set using the mean and standard deviation of the training set\n",
    "X_cv_mapped_scaled = scaler_poly.transform(X_cv_mapped)\n",
    "\n",
    "# Compute the cross validation MSE\n",
    "yhat = model.predict(X_cv_mapped_scaled)\n",
    "print(f\"Cross validation MSE: {mean_squared_error(y_cv, yhat) / 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "คุณจะสังเกตเห็นว่า MSE มีความดีขึ้นอย่างมากสำหรับทั้งชุดฝึกและชุดตรวจสอบข้ามเมื่อคุณเพิ่มพหุนามลำดับที่ 2 คุณอาจต้องการแนะนำพหุนามเพิ่มเติมและดูว่าอันไหนให้ประสิทธิภาพที่ดีที่สุด ดังที่แสดงในคลาส คุณสามารถมี 10 โมเดลที่แตกต่างกันเช่นนี้:\n",
    "\n",
    "<img src='images/C2_W3_poly.png' width=50%>\n",
    "\n",
    "คุณสามารถสร้างลูปที่ประกอบด้วยขั้นตอนทั้งหมดในเซลล์โค้ดก่อนหน้านี้ นี่คือการใช้งานหนึ่งที่เพิ่มฟีเจอร์พหุนามสูงสุดถึงระดับ 10 เราจะพล็อตมันในตอนท้ายเพื่อให้เปรียบเทียบผลลัพธ์สำหรับแต่ละโมเดลได้ง่ายขึ้น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to save the errors, models, and feature transforms\n",
    "train_mses = []\n",
    "cv_mses = []\n",
    "models = []\n",
    "polys = []\n",
    "scalers = []\n",
    "\n",
    "# Loop over 10 times. Each adding one more degree of polynomial higher than the last.\n",
    "for degree in range(1,11):\n",
    "    \n",
    "    # Add polynomial features to the training set\n",
    "    poly = PolynomialFeatures(degree, include_bias=False)\n",
    "    X_train_mapped = poly.fit_transform(x_train)\n",
    "    polys.append(poly)\n",
    "    \n",
    "    # Scale the training set\n",
    "    scaler_poly = StandardScaler()\n",
    "    X_train_mapped_scaled = scaler_poly.fit_transform(X_train_mapped)\n",
    "    scalers.append(scaler_poly)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_mapped_scaled, y_train )\n",
    "    models.append(model)\n",
    "    \n",
    "    # Compute the training MSE\n",
    "    yhat = model.predict(X_train_mapped_scaled)\n",
    "    train_mse = mean_squared_error(y_train, yhat) / 2\n",
    "    train_mses.append(train_mse)\n",
    "    \n",
    "    # Add polynomial features and scale the cross validation set\n",
    "    X_cv_mapped = poly.transform(x_cv)\n",
    "    X_cv_mapped_scaled = scaler_poly.transform(X_cv_mapped)\n",
    "    \n",
    "    # Compute the cross validation MSE\n",
    "    yhat = model.predict(X_cv_mapped_scaled)\n",
    "    cv_mse = mean_squared_error(y_cv, yhat) / 2\n",
    "    cv_mses.append(cv_mse)\n",
    "    \n",
    "# Plot the results\n",
    "degrees=range(1,11)\n",
    "utils.plot_train_cv_mses(degrees, train_mses, cv_mses, title=\"degree of polynomial vs. train and CV MSEs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R83nSGpXGRl2"
   },
   "source": [
    "### การแปลเป็นภาษาไทย\n",
    "\"การเลือกโมเดลที่ดีที่สุด\n",
    "\n",
    "เมื่อเลือกโมเดล คุณควรเลือกโมเดลที่ทำงานได้ดีทั้งในชุดฝึกและชุดตรวจสอบข้ามข้อมูล ซึ่งหมายความว่าโมเดลสามารถเรียนรู้รูปแบบจากชุดฝึกของคุณได้โดยไม่เกิดการโอเวอร์ฟิต หากคุณใช้ค่าเริ่มต้นในห้องปฏิบัติการนี้ คุณจะสังเกตเห็นการลดลงอย่างมากของข้อผิดพลาดในการตรวจสอบข้ามข้อมูลจากโมเดลที่มีดีกรี=1 ไปเป็นดีกรี=2 ตามด้วยเส้นที่ค่อนข้างราบจนถึงดีกรี=5 อย่างไรก็ตาม หลังจากนั้น ข้อผิดพลาดในการตรวจสอบข้ามข้อมูลโดยทั่วไปจะแย่ลงเมื่อคุณเพิ่มคุณลักษณะพหุนามมากขึ้น ด้วยเหตุนี้ คุณสามารถตัดสินใจใช้โมเดลที่มี `cv_mse` ต่ำที่สุดเป็นโมเดลที่เหมาะสมที่สุดสำหรับแอปพลิเคชันของคุณ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model with the lowest CV MSE (add 1 because list indices start at 0)\n",
    "# This also corresponds to the degree of the polynomial added\n",
    "degree = np.argmin(cv_mses) + 1\n",
    "print(f\"Lowest CV MSE is found in the model with degree={degree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "คุณสามารถเผยแพร่ข้อผิดพลาดทั่วไปโดยการคำนวณ MSE ของชุดทดสอบ ตามปกติ คุณควรแปลงข้อมูลนี้ในลักษณะเดียวกับที่คุณทำกับชุดฝึกและชุดตรวจสอบข้าม"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add polynomial features to the test set\n",
    "X_test_mapped = polys[degree-1].transform(x_test)\n",
    "\n",
    "# Scale the test set\n",
    "X_test_mapped_scaled = scalers[degree-1].transform(X_test_mapped)\n",
    "\n",
    "# Compute the test MSE\n",
    "yhat = models[degree-1].predict(X_test_mapped_scaled)\n",
    "test_mse = mean_squared_error(y_test, yhat) / 2\n",
    "\n",
    "print(f\"Training MSE: {train_mses[degree-1]:.2f}\")\n",
    "print(f\"Cross Validation MSE: {cv_mses[degree-1]:.2f}\")\n",
    "print(f\"Test MSE: {test_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5uStJF3GRl2"
   },
   "source": [
    "## Neural Networks\n",
    "\n",
    "The same model selection process can also be used when choosing between different neural network architectures. In this section, you will create the models shown below and apply it to the same regression task above.\n",
    "\n",
    "<img src='images/C2_W3_NN_Arch.png' width=40%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### เตรียมข้อมูล\n",
    "\n",
    "คุณจะใช้ชุดการฝึก การตรวจสอบข้าม และชุดทดสอบเดียวกันที่คุณสร้างขึ้นในส่วนก่อนหน้า จากบทเรียนก่อนหน้านี้ในหลักสูตรนี้ คุณอาจรู้ว่าเครือข่ายประสาทเทียมสามารถเรียนรู้ความสัมพันธ์ที่ไม่เชิงเส้นได้ ดังนั้นคุณสามารถเลือกที่จะข้ามการเพิ่มคุณลักษณะพหุนาม โค้ดจะยังคงรวมอยู่ด้านล่างในกรณีที่คุณต้องการลองใช้ในภายหลังและดูว่าจะมีผลต่อผลลัพธ์ของคุณอย่างไร ค่าเริ่มต้นของ  `degree` ถูกตั้งค่าเป็น `1` เพื่อระบุว่าจะใช้ `x_train`, `x_cv`, และ  `x_test`ตามเดิม (เช่น ไม่มีคุณลักษณะพหุนามเพิ่มเติม)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-armALWpGRl2"
   },
   "outputs": [],
   "source": [
    "# Add polynomial features\n",
    "degree = 1\n",
    "poly = PolynomialFeatures(degree, include_bias=False)\n",
    "X_train_mapped = poly.fit_transform(x_train)\n",
    "X_cv_mapped = poly.transform(x_cv)\n",
    "X_test_mapped = poly.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ต่อไป คุณจะปรับขนาดคุณลักษณะอินพุตเพื่อช่วยให้การไล่ระดับลงมาบรรจบกันได้เร็วขึ้น อีกครั้ง โปรดสังเกตว่าคุณกำลังใช้ค่าเฉลี่ยและส่วนเบี่ยงเบนมาตรฐานที่คำนวณจากชุดฝึกโดยใช้  `transform()` ในชุดตรวจสอบข้ามและชุดทดสอบแทนการใช้  `fit_transform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBn-0m0IGRl2"
   },
   "outputs": [],
   "source": [
    "# Scale the features using the z-score\n",
    "scaler = StandardScaler()\n",
    "X_train_mapped_scaled = scaler.fit_transform(X_train_mapped)\n",
    "X_cv_mapped_scaled = scaler.transform(X_cv_mapped)\n",
    "X_test_mapped_scaled = scaler.transform(X_test_mapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### สร้างและฝึกอบรมโมเดล\n",
    "\n",
    "\n",
    "จากนั้นคุณจะสร้างสถาปัตยกรรมเครือข่ายประสาทเทียมที่แสดงไว้ก่อนหน้านี้  โค้ดมีให้ในฟังก์ชัน  `build_models()` ในไฟล์ `utils.py` กรณีที่คุณต้องการตรวจสอบหรือปรับแต่ง คุณจะใช้สิ่งนั้นในลูปด้านล่างจากนั้นดำเนินการฝึกอบรมโมเดล สำหรับแต่ละโมเดล คุณจะบันทึกข้อผิดพลาดในการฝึกอบรมและการตรวจสอบ (training errors & cross validation errors) ด้วย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists that will contain the errors for each model\n",
    "nn_train_mses = []\n",
    "nn_cv_mses = []\n",
    "\n",
    "# Build the models\n",
    "nn_models = utils.build_models()\n",
    "\n",
    "# Loop over the the models\n",
    "for model in nn_models:\n",
    "    \n",
    "    # Setup the loss and optimizer\n",
    "    model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "    )\n",
    "\n",
    "    print(f\"Training {model.name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        X_train_mapped_scaled, y_train,\n",
    "        epochs=300,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    print(\"Done!\\n\")\n",
    "\n",
    "    \n",
    "    # Record the training MSEs\n",
    "    yhat = model.predict(X_train_mapped_scaled)\n",
    "    train_mse = mean_squared_error(y_train, yhat) / 2\n",
    "    nn_train_mses.append(train_mse)\n",
    "    \n",
    "    # Record the cross validation MSEs \n",
    "    yhat = model.predict(X_cv_mapped_scaled)\n",
    "    cv_mse = mean_squared_error(y_cv, yhat) / 2\n",
    "    nn_cv_mses.append(cv_mse)\n",
    "\n",
    "    \n",
    "# print results\n",
    "print(\"RESULTS:\")\n",
    "for model_num in range(len(nn_train_mses)):\n",
    "    print(\n",
    "        f\"Model {model_num+1}: Training MSE: {nn_train_mses[model_num]:.2f}, \" +\n",
    "        f\"CV MSE: {nn_cv_mses[model_num]:.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากข้อผิดพลาดที่บันทึกไว้ คุณสามารถตัดสินใจได้ว่าโมเดลใดดีที่สุดสำหรับแอปพลิเคชันของคุณ ดูผลลัพธ์ข้างต้นและดูว่าคุณเห็นด้วยกับ `model_num`  ที่เลือกด้านล่างหรือไม่ สุดท้าย คุณจะคำนวณข้อผิดพลาดในการทดสอบเพื่อประมาณการว่ามันจะสรุปทั่วไปกับตัวอย่างใหม่ได้ดีแค่ไหน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model with the lowest CV MSE\n",
    "model_num = 3\n",
    "\n",
    "# Compute the test MSE\n",
    "yhat = nn_models[model_num-1].predict(X_test_mapped_scaled)\n",
    "test_mse = mean_squared_error(y_test, yhat) / 2\n",
    "\n",
    "print(f\"Selected Model: {model_num}\")\n",
    "print(f\"Training MSE: {nn_train_mses[model_num-1]:.2f}\")\n",
    "print(f\"Cross Validation MSE: {nn_cv_mses[model_num-1]:.2f}\")\n",
    "print(f\"Test MSE: {test_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## การจำแนกประเภท\n",
    "\n",
    "ในส่วนสุดท้ายของห้องปฏิบัติการนี้ คุณจะฝึกฝนการประเมินและเลือกโมเดลในการทำภารกิจการจำแนกประเภท กระบวนการนี้จะคล้ายกัน โดยมีความแตกต่างหลักอยู่ที่การคำนวณข้อผิดพลาด คุณจะเห็นในส่วนต่อไปนี้"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### โหลดชุดข้อมูล\n",
    "\n",
    "ขั้นแรก คุณจะโหลดชุดข้อมูลสำหรับงานการจำแนกประเภทแบบไบนารี มีตัวอย่าง 200 ตัวอย่างของสองคุณลักษณะอินพุต (`x1` และ  `x2`), และเป้าหมาย `y` ที่เป็น `0` หรือ `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from a text file\n",
    "data = np.loadtxt('./data/data_w3_ex2.csv', delimiter=',')\n",
    "\n",
    "# Split the inputs and outputs into separate arrays\n",
    "x_bc = data[:,:-1]\n",
    "y_bc = data[:,-1]\n",
    "\n",
    "# Convert y into 2-D because the commands later will require it (x is already 2-D)\n",
    "y_bc = np.expand_dims(y_bc, axis=1)\n",
    "\n",
    "print(f\"the shape of the inputs x is: {x_bc.shape}\")\n",
    "print(f\"the shape of the targets y is: {y_bc.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "คุณสามารถพล็อตชุดข้อมูลเพื่อตรวจสอบว่าตัวอย่างถูกแยกออกอย่างไร"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_bc_dataset(x=x_bc, y=y_bc, title=\"x1 vs. x2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### แบ่งและเตรียมชุดข้อมูล\n",
    "\n",
    "ต่อไป คุณจะสร้างชุดฝึก ชุดตรวจสอบข้าม และชุดทดสอบ คุณจะใช้สัดส่วน 60/20/20 เดิม คุณจะปรับขนาดคุณลักษณะเช่นเดียวกับที่คุณทำในส่วนก่อนหน้า"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get 60% of the dataset as the training set. Put the remaining 40% in temporary variables.\n",
    "x_bc_train, x_, y_bc_train, y_ = train_test_split(x_bc, y_bc, test_size=0.40, random_state=1)\n",
    "\n",
    "# Split the 40% subset above into two: one half for cross validation and the other for the test set\n",
    "x_bc_cv, x_bc_test, y_bc_cv, y_bc_test = train_test_split(x_, y_, test_size=0.50, random_state=1)\n",
    "\n",
    "# Delete temporary variables\n",
    "del x_, y_\n",
    "\n",
    "print(f\"the shape of the training set (input) is: {x_bc_train.shape}\")\n",
    "print(f\"the shape of the training set (target) is: {y_bc_train.shape}\\n\")\n",
    "print(f\"the shape of the cross validation set (input) is: {x_bc_cv.shape}\")\n",
    "print(f\"the shape of the cross validation set (target) is: {y_bc_cv.shape}\\n\")\n",
    "print(f\"the shape of the test set (input) is: {x_bc_test.shape}\")\n",
    "print(f\"the shape of the test set (target) is: {y_bc_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "\n",
    "# Initialize the class\n",
    "scaler_linear = StandardScaler()\n",
    "\n",
    "# Compute the mean and standard deviation of the training set then transform it\n",
    "x_bc_train_scaled = scaler_linear.fit_transform(x_bc_train)\n",
    "x_bc_cv_scaled = scaler_linear.transform(x_bc_cv)\n",
    "x_bc_test_scaled = scaler_linear.transform(x_bc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### การประเมินข้อผิดพลาดสำหรับโมเดลการจำแนกประเภท\n",
    "ในส่วนก่อนหน้าเกี่ยวกับโมเดลการถดถอย คุณใช้ค่าความคลาดเคลื่อนกำลังสองเฉลี่ย (mean squared error) เพื่อวัดประสิทธิภาพของโมเดลของคุณ สำหรับการจำแนกประเภท คุณสามารถคำนวณตัวชี้วัดที่คล้ายคลึงกันได้โดยการคำนวณสัดส่วนของข้อมูลที่โมเดลจัดประเภทผิดตัวอย่างเช่น สมมติว่าโมเดลของคุณทำนายผิดสำหรับตัวอย่าง 2 จาก 5 ตัวอย่าง คุณจะรายงานข้อผิดพลาดที่  `40%` หรือ `0.4`โค้ดด้านล่างแสดงวิธีการคำนวณนี้โดยใช้ลูป for และฟังก์ชัน [`mean()`](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) ของ Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample model output\n",
    "probabilities = np.array([0.2, 0.6, 0.7, 0.3, 0.8])\n",
    "\n",
    "# Apply a threshold to the model output. If greater than 0.5, set to 1. Else 0.\n",
    "predictions = np.where(probabilities >= 0.5, 1, 0)\n",
    "\n",
    "# Ground truth labels\n",
    "ground_truth = np.array([1, 1, 1, 1, 1])\n",
    "\n",
    "# Initialize counter for misclassified data\n",
    "misclassified = 0\n",
    "\n",
    "# Get number of predictions\n",
    "num_predictions = len(predictions)\n",
    "\n",
    "# Loop over each prediction\n",
    "for i in range(num_predictions):\n",
    "    \n",
    "    # Check if it matches the ground truth\n",
    "    if predictions[i] != ground_truth[i]:\n",
    "        \n",
    "        # Add one to the counter if the prediction is wrong\n",
    "        misclassified += 1\n",
    "\n",
    "# Compute the fraction of the data that the model misclassified\n",
    "fraction_error = misclassified/num_predictions\n",
    "\n",
    "print(f\"probabilities: {probabilities}\")\n",
    "print(f\"predictions with threshold=0.5: {predictions}\")\n",
    "print(f\"targets: {ground_truth}\")\n",
    "print(f\"fraction of misclassified data (for-loop): {fraction_error}\")\n",
    "print(f\"fraction of misclassified data (with np.mean()): {np.mean(predictions != ground_truth)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### สร้างและฝึกโมเดล\n",
    "คุณจะใช้โครงสร้างเครือข่ายประสาทเทียมแบบเดียวกับในหัวข้อก่อนหน้า เพื่อให้คุณสามารถเรียกฟังก์ชัน `build_models()` อีกครั้งเพื่อสร้างโมเดลใหม่เหล่านี้\n",
    "\n",
    "คุณจะปฏิบัติตามแนวทางที่แนะนำจากสัปดาห์ที่แล้วโดยใช้ฟังก์ชันการกระตุ้นแบบ `linear` สำหรับชั้นเอาต์พุต (แทนที่จะเป็น `sigmoid`) จากนั้นตั้งค่า `from_logits=True` เมื่อประกาศฟังก์ชันการสูญเสียของโมเดล เนื่องจากเป็นปัญหาการจำแนกประเภทแบบไบนารี คุณจะใช้ [binary crossentropy loss](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy) \n",
    "\n",
    "หลังจากการฝึก คุณจะใช้ [sigmoid function](https://www.tensorflow.org/api_docs/python/tf/math/sigmoid) เพื่อแปลงผลลัพธ์ของโมเดลเป็นความน่าจะเป็น จากนั้นคุณสามารถตั้งค่าเกณฑ์ (threshold) และรับสัดส่วนของตัวอย่างที่จัดประเภทผิดจากชุดข้อมูลฝึกอบรมและชุดข้อมูลตรวจสอบข้าม\n",
    "\n",
    "คุณสามารถดูทั้งหมดนี้ได้ในเซลล์โค้ดด้านล่าง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists that will contain the errors for each model\n",
    "nn_train_error = []\n",
    "nn_cv_error = []\n",
    "\n",
    "# Build the models\n",
    "models_bc = utils.build_models()\n",
    "\n",
    "# Loop over each model\n",
    "for model in models_bc:\n",
    "    \n",
    "    # Setup the loss and optimizer\n",
    "    model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    )\n",
    "\n",
    "    print(f\"Training {model.name}...\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        x_bc_train_scaled, y_bc_train,\n",
    "        epochs=200,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    print(\"Done!\\n\")\n",
    "    \n",
    "    # Set the threshold for classification\n",
    "    threshold = 0.5\n",
    "    \n",
    "    # Record the fraction of misclassified examples for the training set\n",
    "    yhat = model.predict(x_bc_train_scaled)\n",
    "    yhat = tf.math.sigmoid(yhat)\n",
    "    yhat = np.where(yhat >= threshold, 1, 0)\n",
    "    train_error = np.mean(yhat != y_bc_train)\n",
    "    nn_train_error.append(train_error)\n",
    "\n",
    "    # Record the fraction of misclassified examples for the cross validation set\n",
    "    yhat = model.predict(x_bc_cv_scaled)\n",
    "    yhat = tf.math.sigmoid(yhat)\n",
    "    yhat = np.where(yhat >= threshold, 1, 0)\n",
    "    cv_error = np.mean(yhat != y_bc_cv)\n",
    "    nn_cv_error.append(cv_error)\n",
    "\n",
    "# Print the result\n",
    "for model_num in range(len(nn_train_error)):\n",
    "    print(\n",
    "        f\"Model {model_num+1}: Training Set Classification Error: {nn_train_error[model_num]:.5f}, \" +\n",
    "        f\"CV Set Classification Error: {nn_cv_error[model_num]:.5f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากผลลัพธ์ข้างต้น คุณสามารถเลือกได้ว่าอันไหนทำได้ดีที่สุด หากมีการเสมอกันในข้อผิดพลาดของชุดการตรวจสอบข้าม คุณสามารถเพิ่มเกณฑ์อื่นเพื่อตัดสินใจได้ ตัวอย่างเช่น คุณสามารถเลือกอันที่มีข้อผิดพลาดในการฝึกน้อยกว่า วิธีการทั่วไปอีกวิธีหนึ่งคือการเลือกโมเดลที่เล็กกว่าเนื่องจากช่วยประหยัดทรัพยากรการคำนวณ ในตัวอย่างของเรา โมเดล 1 เล็กที่สุดและโมเดล 3 ใหญ่ที่สุด\n",
    "\n",
    "สุดท้าย คุณสามารถคำนวณข้อผิดพลาดของการทดสอบเพื่อรายงานข้อผิดพลาดในการทั่วไปของโมเดล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model with the lowest error\n",
    "model_num = 3\n",
    "\n",
    "# Compute the test error\n",
    "yhat = models_bc[model_num-1].predict(x_bc_test_scaled)\n",
    "yhat = tf.math.sigmoid(yhat)\n",
    "yhat = np.where(yhat >= threshold, 1, 0)\n",
    "nn_test_error = np.mean(yhat != y_bc_test)\n",
    "\n",
    "print(f\"Selected Model: {model_num}\")\n",
    "print(f\"Training Set Classification Error: {nn_train_error[model_num-1]:.4f}\")\n",
    "print(f\"CV Set Classification Error: {nn_cv_error[model_num-1]:.4f}\")\n",
    "print(f\"Test Set Classification Error: {nn_test_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## สรุป\n",
    "\n",
    "ในห้องปฏิบัติการนี้ คุณได้ฝึกฝนการประเมินประสิทธิภาพของโมเดลและการเลือกการกำหนดค่าโมเดลที่แตกต่างกัน คุณได้แยกชุดข้อมูลของคุณออกเป็นชุดฝึก ชุดตรวจสอบข้าม และชุดทดสอบ และได้เห็นวิธีการใช้แต่ละชุดในแอปพลิเคชันการเรียนรู้ของเครื่อง ในส่วนถัดไปของหลักสูตร คุณจะเห็นเคล็ดลับเพิ่มเติมเกี่ยวกับวิธีการปรับปรุงโมเดลของคุณโดยการวินิจฉัยอคติและความแปรปรวน สู้ๆ!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
