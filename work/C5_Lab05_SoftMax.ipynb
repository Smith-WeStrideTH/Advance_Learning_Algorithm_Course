{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Optional Lab - ฟังก์ชันซอฟต์แม็กซ์\n",
    "ในห้องปฏิบัติการนี้ เราจะสำรวจฟังก์ชันซอฟต์แม็กซ์ ฟังก์ชันนี้ใช้ในทั้งการถดถอยซอฟต์แม็กซ์และในเครือข่ายประสาทเทียมเมื่อแก้ปัญหาการจำแนกประเภทหลายคลาส\n",
    "<center>  <img  src=\"./images/C2_W2_Softmax_Header_v1.png\" width=\"600\" />  <center/>\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "try:\n",
    "  %matplotlib widget\n",
    "  print(\"widget is already installed\")\n",
    "except:\n",
    "  print(\"widget is not been installed, install now..\")\n",
    "  !pip install ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/Smith-WeStrideTH/Advance_Learning_Algorithm_Course/refs/heads/main/work/deeplearning.mplstyle'\n",
    "url2 = 'https://raw.githubusercontent.com/Smith-WeStrideTH/Advance_Learning_Algorithm_Course/refs/heads/main/work/lab_utils_common_C5.py'\n",
    "url3 = 'https://raw.githubusercontent.com/Smith-WeStrideTH/Advance_Learning_Algorithm_Course/refs/heads/main/work/autils.py'\n",
    "url4 = 'https://raw.githubusercontent.com/Smith-WeStrideTH/Advance_Learning_Algorithm_Course/refs/heads/main/work/lab_utils_softmax.py'\n",
    "\n",
    "response = requests.get(url)\n",
    "with open('deeplearning.mplstyle', 'wb') as f:\n",
    "  f.write(response.content)\n",
    "\n",
    "response = requests.get(url2)\n",
    "with open('lab_utils_common.py', 'wb') as f:\n",
    "  f.write(response.content)\n",
    "\n",
    "response = requests.get(url3)\n",
    "with open('autils.py', 'wb') as f:\n",
    "  f.write(response.content)\n",
    "\n",
    "response = requests.get(url4)\n",
    "with open('lab_utils_softmax.py', 'wb') as f:\n",
    "  f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from sklearn.datasets import make_blobs\n",
    "%matplotlib widget\n",
    "from matplotlib.widgets import Slider\n",
    "from lab_utils_common import dlc\n",
    "from lab_utils_softmax import plt_softmax\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **หมายเหตุ**: โดยปกติ ในหลักสูตรนี้ โน้ตบุ๊กจะใช้รูปแบบการเริ่มนับด้วย 0 และสิ้นสุดด้วย N-1 ซึ่งเขียนเป็น $\\sum_{i=0}^{N-1}$, ในขณะที่การบรรยายจะเริ่มด้วย 1 และสิ้นสุดด้วย N ซึ่งเขียนเป็น  $\\sum_{i=1}^{N}$. เนื่องจากโค้ดโดยทั่วไปจะเริ่มการวนซ้ำด้วย 0 ในขณะที่ในการบรรยาย การนับจาก 1 ถึง N จะทำให้สมการมีความชัดเจนและกระชับมากขึ้น โน้ตบุ๊กนี้มีสมการมากกว่าปกติสำหรับห้องปฏิบัติการ ดังนั้นจึงจะขัดกับรูปแบบนี้และจะนับจาก 1 ถึง N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Softmax Function\n",
    "ในทั้งการถดถอยซอฟต์แม็กซ์และเครือข่ายประสาทเทียมที่มีผลลัพธ์ซอฟต์แม็กซ์ จะมีการสร้างผลลัพธ์ N ผลลัพธ์และเลือกผลลัพธ์หนึ่งเป็นหมวดหมู่ที่ทำนายได้ ในทั้งสองกรณีจะมีการสร้างเวกเตอร์ $\\mathbf{z}$ โดยใช้ฟังก์ชันเชิงเส้นซึ่งนำไปใช้กับฟังก์ชันซอฟต์แม็กซ์ ฟังก์ชันซอฟต์แม็กซ์จะแปลง $\\mathbf{z}$  เป็นการแจกแจงความน่าจะเป็นตามที่อธิบายไว้ด้านล่าง หลังจากใช้ซอฟต์แม็กซ์ ผลลัพธ์แต่ละรายการจะอยู่ระหว่าง 0 ถึง 1 และผลลัพธ์จะบวกกันเป็น 1 เพื่อให้สามารถตีความได้ว่าเป็นความน่าจะเป็น อินพุตที่ใหญ่กว่าจะสอดคล้องกับความน่าจะเป็นของผลลัพธ์ที่ใหญ่กว่า\n",
    "<center>  <img  src=\"./images/C2_W2_SoftmaxReg_NN.png\" width=\"600\" />  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax สามารถเขียนได้ดังนี้:\n",
    "$$a_j = \\frac{e^{z_j}}{ \\sum_{k=1}^{N}{e^{z_k} }} \\tag{1}$$\n",
    "The output $\\mathbf{a}$ is a vector of length N, so for softmax regression, you could also write:\n",
    "\\begin{align}\n",
    "\\mathbf{a}(x) =\n",
    "\\begin{bmatrix}\n",
    "P(y = 1 | \\mathbf{x}; \\mathbf{w},b) \\\\\n",
    "\\vdots \\\\\n",
    "P(y = N | \\mathbf{x}; \\mathbf{w},b)\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\frac{1}{ \\sum_{k=1}^{N}{e^{z_k} }}\n",
    "\\begin{bmatrix}\n",
    "e^{z_1} \\\\\n",
    "\\vdots \\\\\n",
    "e^{z_{N}} \\\\\n",
    "\\end{bmatrix} \\tag{2}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ซึ่งแสดงให้เห็นว่าผลลัพธ์เป็นเวกเตอร์ของความน่าจะเป็น รายการแรกคือความน่าจะเป็นที่อินพุตเป็นหมวดหมู่แรกเมื่อกำหนดอินพุต $\\mathbf{x}$ และพารามิเตอร์  $\\mathbf{w}$ และ $\\mathbf{b}$.  \n",
    "มาสร้างการนำไปใช้ NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax(z):\n",
    "    ez = np.exp(z)              #element-wise exponenial\n",
    "    sm = ez/np.sum(ez)\n",
    "    return(sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ด้านล่าง ให้เปลี่ยนค่าของอินพุต `z` โดยใช้แถบเลื่อน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "plt_softmax(my_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เมื่อคุณกำลังเปลี่ยนค่าของ z's ด้านบน มีสิ่งสำคัญบางอย่างที่ควรทราบ:\n",
    "* เอ็กซ์โปเนนเชียลในตัวเศษของซอฟต์แม็กซ์จะขยายความแตกต่างเล็กน้อยในค่า \n",
    "* ค่าผลลัพธ์รวมเป็นหนึ่ง\n",
    "* ซอฟต์แม็กซ์ครอบคลุมเอาต์พุตทั้งหมด การเปลี่ยนแปลงใน  `z0` เช่น จะเปลี่ยนค่าของ `a0`-`a3`. เปรียบเทียบกับการกระตุ้นอื่นๆ เช่น ReLU หรือ Sigmoid ที่มีอินพุตเดียวและเอาต์พุตเดียว"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cost\n",
    "<center> <img  src=\"./images/C2_W2_SoftMaxCost_v1.png\" width=\"400\" />    <center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ฟังก์ชันการสูญเสียที่เกี่ยวข้องกับซอฟต์แม็กซ์ การสูญเสียข้ามเอนโทรปี คือ:\\begin{equation}\n",
    "  L(\\mathbf{a},y)=\\begin{cases}\n",
    "    -log(a_1), & \\text{if $y=1$}.\\\\\n",
    "        &\\vdots\\\\\n",
    "     -log(a_N), & \\text{if $y=N$}\n",
    "  \\end{cases} \\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "โดยที่ y คือหมวดหมู่เป้าหมายสำหรับตัวอย่างนี้ และ $\\mathbf{a}$  คือผลลัพธ์ของฟังก์ชันซอฟต์แม็กซ์ โดยเฉพาะค่าใน  $\\mathbf{a}$ เป็นความน่าจะเป็นที่รวมกันเป็นหนึ่ง\n",
    ">**การทบทวน:** ในหลักสูตรนี้ การสูญเสีย (Loss) เป็นสำหรับตัวอย่างหนึ่ง ในขณะที่ต้นทุน (Cost) ครอบคลุมตัวอย่างทั้งหมด\n",
    " \n",
    " \n",
    "โปรดทราบใน (3) ข้างต้น เฉพาะบรรทัดที่สอดคล้องกับเป้าหมายเท่านั้นที่มีส่วนทำให้เกิดการสูญเสีย บรรทัดอื่น ๆ มีค่าเป็นศูนย์ เพื่อเขียนสมการต้นทุน เราต้องการ 'ฟังก์ชันตัวบ่งชี้' ที่จะมีค่าเป็น 1 เมื่อดัชนีตรงกับเป้าหมายและเป็นศูนย์ในกรณีอื่น ๆ\n",
    "    $$\\mathbf{1}\\{y == n\\} = =\\begin{cases}\n",
    "    1, & \\text{if $y==n$}.\\\\\n",
    "    0, & \\text{otherwise}.\n",
    "  \\end{cases}$$\n",
    "ตอนนี้ cost คือ:\n",
    "\\begin{align}\n",
    "J(\\mathbf{w},b) = -\\frac{1}{m} \\left[ \\sum_{i=1}^{m} \\sum_{j=1}^{N}  1\\left\\{y^{(i)} == j\\right\\} \\log \\frac{e^{z^{(i)}_j}}{\\sum_{k=1}^N e^{z^{(i)}_k} }\\right] \\tag{4}\n",
    "\\end{align}\n",
    "\n",
    "โดยที่  $m$ คือจำนวนตัวอย่าง, $N$ คือจำนวนผลลัพธ์ นี่คือค่าเฉลี่ยของการสูญเสียทั้งหมด\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "ห้องปฏิบัติการนี้จะกล่าวถึงสองวิธีในการนำฟังก์ชันซอฟต์แม็กซ์และการสูญเสียแบบครอสเอนโทรปีไปใช้ใน TensorFlow ซึ่งเป็นวิธีที่ 'ชัดเจน' และวิธีที่ 'เป็นที่ต้องการ' วิธีแรกนั้นตรงไปตรงมาที่สุดในขณะที่วิธีหลังนั้นมีความเสถียรทางตัวเลขมากกว่า\n",
    "\n",
    "มาเริ่มกันด้วยการสร้างชุดข้อมูลเพื่อฝึกโมเดลการจำแนกประเภทหลายคลาส"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make  dataset for example\n",
    "centers = [[-5, 2], [-2, -2], [1, 2], [5, -2]]\n",
    "X_train, y_train = make_blobs(n_samples=2000, centers=centers, cluster_std=1.0,random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The *Obvious* organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โมเดลด้านล่างนี้ถูกนำไปใช้กับซอฟต์แม็กซ์เป็นฟังก์ชันการกระตุ้นในเลเยอร์สุดท้าย ฟังก์ชันการสูญเสียถูกระบุแยกกันในคำสั่ง `compile`  \n",
    "\n",
    "ฟังก์ชันการสูญเสียคือ  `SparseCategoricalCrossentropy` การสูญเสียนี้มีการอธิบายใน (3) ข้างต้น ในโมเดลนี้ ซอฟต์แม็กซ์เกิดขึ้นในเลเยอร์สุดท้าย ฟังก์ชันการสูญเสียรับเอาผลลัพธ์ซอฟต์แม็กซ์ซึ่งเป็นเวกเตอร์ของความน่าจะเป็น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [ \n",
    "        Dense(25, activation = 'relu'),\n",
    "        Dense(15, activation = 'relu'),\n",
    "        Dense(4, activation = 'softmax')    # < softmax activation here\n",
    "    ]\n",
    ")\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=10\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เนื่องจากซอฟต์แม็กซ์ถูกรวมเข้ากับเลเยอร์เอาต์พุต ผลลัพธ์จึงเป็นเวกเตอร์ของความน่าจะเป็น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_nonpreferred = model.predict(X_train)\n",
    "print(p_nonpreferred [:2])\n",
    "print(\"largest value\", np.max(p_nonpreferred), \"smallest value\", np.min(p_nonpreferred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preferred <img align=\"Right\" src=\"./images/C2_W2_softmax_accurate_v1.png\"  style=\" width:400px; padding: 10px 20px ; \">\n",
    "จากการบรรยายคุณอาจจำได้ว่าจะได้ผลลัพธ์ที่เสถียรและแม่นยำยิ่งขึ้นหากรวมซอฟต์แม็กซ์และการสูญเสียเข้าด้วยกันระหว่างการฝึกอบรม การจัดระเบียบ 'ที่ต้องการ' แสดงไว้ที่นี่"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การแปลเป็นภาษาไทย\n",
    "\"ในองค์กรที่ต้องการ ชั้นสุดท้ายจะมีการกระตุ้นเชิงเส้น ผลลัพธ์ในรูปแบบนี้เรียกว่า logits เนื่องจากเหตุผลทางประวัติศาสตร์ ฟังก์ชันการสูญเสียมีอาร์กิวเมนต์เพิ่มเติม: `from_logits = True` ซึ่งแจ้งให้ฟังก์ชันการสูญเสียทราบว่าควรมีการรวมการดำเนินการซอฟต์แม็กซ์ไว้ในการคำนวณการสูญเสีย ซึ่งช่วยให้สามารถนำไปใช้ได้อย่างเหมาะสม"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "preferred_model = Sequential(\n",
    "    [ \n",
    "        Dense(25, activation = 'relu'),\n",
    "        Dense(15, activation = 'relu'),\n",
    "        Dense(4, activation = 'linear')   #<-- Note\n",
    "    ]\n",
    ")\n",
    "preferred_model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  #<-- Note\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "preferred_model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=10\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### การจัดการผลลัพธ์\n",
    "\n",
    "โปรดสังเกตว่าในโมเดลที่ต้องการ ผลลัพธ์ไม่ได้เป็นความน่าจะเป็น แต่สามารถอยู่ในช่วงตั้งแต่จำนวนลบขนาดใหญ่ไปจนถึงจำนวนบวกขนาดใหญ่ ผลลัพธ์จะต้องถูกส่งผ่านซอฟต์แม็กซ์เมื่อทำการทำนายที่คาดว่าจะเป็นความน่าจะเป็น\n",
    "\n",
    "มาดูผลลัพธ์ของโมเดลที่ต้องการกัน:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_preferred = preferred_model.predict(X_train)\n",
    "print(f\"two example output vectors:\\n {p_preferred[:2]}\")\n",
    "print(\"largest value\", np.max(p_preferred), \"smallest value\", np.min(p_preferred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ผลลัพธ์การทำนายไม่ใช่ความน่าจะเป็น!\n",
    "\n",
    "หากต้องการให้ผลลัพธ์เป็นความน่าจะเป็น ผลลัพธ์ควรได้รับการประมวลผลโดย [softmax](https://www.tensorflow.org/api_docs/python/tf/nn/softmax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_preferred = tf.nn.softmax(p_preferred).numpy()\n",
    "print(f\"two example output vectors:\\n {sm_preferred[:2]}\")\n",
    "print(\"largest value\", np.max(sm_preferred), \"smallest value\", np.min(sm_preferred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เพื่อเลือกหมวดหมู่ที่เป็นไปได้มากที่สุด ไม่จำเป็นต้องใช้ซอฟต์แม็กซ์ สามารถหาดัชนีของผลลัพธ์ที่ใหญ่ที่สุดโดยใช้ [np.argmax()](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print( f\"{p_preferred[i]}, category: {np.argmax(p_preferred[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparseCategorialCrossentropy หรือ CategoricalCrossEntropy\n",
    "Tensorflow มีสองรูปแบบที่เป็นไปได้สำหรับค่าเป้าหมายและการเลือกการสูญเสียจะกำหนดรูปแบบที่คาดหวัง\n",
    "- SparseCategorialCrossentropy: คาดหวังว่าเป้าหมายจะเป็นจำนวนเต็มที่สอดคล้องกับดัชนี ตัวอย่างเช่น หากมีค่าเป้าหมายที่เป็นไปได้ 10 ค่า y จะอยู่ระหว่าง 0 ถึง 9 \n",
    "- CategoricalCrossEntropy:  คาดหวังว่าค่าเป้าหมายของตัวอย่างจะเป็นการเข้ารหัสแบบ one-hot โดยค่าที่ดัชนีเป้าหมายจะเป็น 1 ในขณะที่รายการ N-1 อื่น ๆ จะเป็นศูนย์ ตัวอย่างที่มีค่าเป้าหมายที่เป็นไปได้ 10 ค่า โดยเป้าหมายคือ 2 จะเป็น [0,0,1,0,0,0,0,0,0,0].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ขอแสดงความยินดี!\n",
    "\n",
    "ในห้องปฏิบัติการนี้ คุณได้\n",
    "-ทำความคุ้นเคยกับฟังก์ชันซอฟต์แม็กซ์และการใช้งานในการถดถอยซอฟต์แม็กซ์และการกระตุ้นซอฟต์แม็กซ์ในเครือข่ายประสาทเทียม\n",
    "- เรียนรู้การสร้างแบบจำลองที่เป็นที่นิยมใน TensorFlow:\n",
    "    - ไม่ใช้การกระตุ้นในเลเยอร์สุดท้าย (เหมือนกับการกระตุ้นเชิงเส้น)\n",
    "    - ฟังก์ชันการสูญเสีย SparseCategoricalCrossentropy\n",
    "    - ใช้ from_logits=True \n",
    "- ตระหนักว่าไม่เหมือน ReLU และ Sigmoid ซอฟต์แม็กซ์ครอบคลุมหลายเอาต์พุต"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
